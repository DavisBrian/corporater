# Data Transformation

```{r, message=FALSE}
library(tidyverse)
```

## Tibbles

Tibbles **are** data frames, but they tweak some older behaviors to make life a little easier. R is an old language, and some things that were useful 10 or 20 years ago now get in your way. It’s difficult to change base R without breaking existing code, so most innovation occurs in packages.

```{block2, type='rmdimportant'}
See Chapter 7 in [R for Data Science](http://r4ds.had.co.nz/tibbles.html) and `vignette("tibble")` for a more complete description of tibbles.
```


Key advantages of tibbles:

-    Never changes the types of the inputs (e.g. it never converts strings to factors!).
-    Never changes the names of variables.
-    Never creates row names.
-    Refined printing to the console:
     -   only prints the first 10 rows
     -   shows the data type of each column
     -   highlights missing values
     -   aligns numeric data
-   Enhanced subsetting

When creating a tibble:

-   it will **ONLY** recycle inputs of length 1
-   you can refer to variables you just created

```{r}
mytibble <- tibble(
  x = 1:5, 
  y = 1, 
  z = x ^ 2 + y
)

# versus

mydf <- data.frame(
  x = 1:5,
  y = 1
)

mydf$z <- mydf$x^2 + mydf$y

mytibble
mydf

```

For the most part you can use data.frames and tibbles interchangeably.  However, some older functions in base R do not work properly with tibbles.  This is because of the `[` subset operator.  As we saw in subsetting, if you return a single column with `[` on a data.frame you will get a vector back instead of a single column data.frame. Tibbles always return tibbles and never a vector. 

You can convert a data frame to a tibble with `as_tibble()`, while you can coerce a tibble to a data frame with `as.data.fame()`.

```{block2, type='rmdimportant'}
dplyr functions never modify their inputs, so if you want to save the result, you’ll need to use the assignment operator, `<-`
```

## Filter rows with `filter()`

`filter()` allows you to subset observations based on their values. The first argument is the name of the data frame. The second and subsequent arguments are the expressions that filter the data frame. 

## Arrange rows with `arrange()`

`arrange()` works similarly to `filter()` except that instead of selecting rows, it changes their order. It takes a data frame and a set of column names (or more complicated expressions) to order by. If you provide more than one column name, each additional column will be used to break ties in the values of preceding columns.

Notes:

-    Use `desc()` to re-order by a column in descending order:
-    Missing values are always sorted at the end.


## Select columns with `select()`

It’s not uncommon to get datasets with hundreds or even thousands of variables. In this case, the first challenge is often narrowing in on the variables you’re actually interested in. `select()` allows you to rapidly zoom in on a useful subset using operations based on the names of the variables.

There are a number of helper functions you can use within select():

-    everything(): all variables or everything else not already selected / deselected.
-    starts_with(): start with a prefix.
-    ends_with(): ends with a prefix
-    contains(): contains a literal string
-    matches(): match a regular expression. 
-    num_range(): a numerical range like x1, x2, x3.
<!-- -    one_of(): variable in a character vector -->

```{block type='rmdnote'}
Closely related to `select()` is `rename()` for renaming columns.
```


## Add new variables with `mutate()`

Besides selecting sets of existing columns, it’s often useful to add new columns that are functions of existing columns. `mutate()` always adds new columns at the end of your dataset so we’ll start by creating a narrower dataset so we can see the new variables. Remember that when you’re in RStudio, the easiest way to see all the columns is `View()`.

Because we have are using tibbles you can refer to columns you just created.

```{block type='rmdtip'}
If you only want to keep the new variables, use `transmute()`.
```

## Pipes

```{block2, type='rmdimportant'}
See Chapter 14 in [R for Data Science](http://r4ds.had.co.nz/pipes.html).
```

Typically it takes a series of operations to go from raw data to meaningful analysis. There are (at least) four ways to to do this:

-   Save each intermediate step as a new object.
-   Overwrite the original object many times.
-   Compose functions.
-   Use pipes

Each have the place and utility.  None are perfect for every situation.  We’ll use piping frequently from now on because it considerably improves the readability of code.

### Intermediate steps

Simplest approach is to create a new object at each step.  This method tends to clutter the code with unimportant, and uninformative names.  Also, each object eats up memory, which becomes an issue as data set sizes grow large.

Rule of thumb:  If there is a natural new name it may be an appropriate method.  If the natural name is to increment a counter on the end of the original variable a different method is generally preferable.

### Overwrite the original

Instead of creating intermediate objects at each step, we could overwrite the original object.

This is less typing (and less thinking), so you’re less likely to make mistakes. However, there are two problems:

-    Debugging is painful: if you make a mistake you’ll need to re-run the complete pipeline from the beginning.
-    The repetition of the object being transformed (we’ve written foo_foo six times!) obscures what’s changing on each line.


```{block type='rmdnote'}
A common method is to combine the above methods and use an temporary variable name for the intermediate steps such a "tmp"" or ".".
```

### Function composition

Another approach is to abandon assignment and just string the function calls together.  Here the disadvantage is that you have to read from inside-out, from right-to-left, and that the arguments end up spread far apart (evocatively called the dagwood sandwich problem). In short, this code is hard for a human to consume.

```{block type='rmdnote'}
This method is generally not appropriate if you need to nest more than two functions together.  However, it is appropriate in many cases. (e.g. sum(is.na(x)) to find the number of missing values in x)
```

### Use the pipe operator `%>%`

Finally, we can use the pipe.  This is my favorite form, because it focuses on verbs (what we are doing), not nouns (what we are doing it on). You can read this series of function compositions like it’s a set of imperative actions.

The pipe works by performing a “lexical transformation”.  Behind the scenes, `magrittr` reassembles the code in the pipe to a form that works by overwriting an intermediate object. This means that pipes won't work for two classes of functions:

1.    Functions that use the current environment. (e.g. `assign`, `with`,`get` or `load`)
2.    Functions that use lazy evaluation. In R, function arguments are only computed when the function uses them, not prior to calling the function. The pipe computes each element in turn, so you can’t rely on this behavior. (e.g. `tryCatch`, `try`, `suppressMessages`)

The pipe is a powerful tool, but it’s not the only tool at your disposal, and it doesn’t solve every problem! Pipes are most useful for rewriting a fairly short linear sequence of operations. I think you should reach for another tool when:

-    Your pipes are longer than (say) ten steps. In that case, create intermediate objects with meaningful names. That will make debugging easier, because you can more easily check the intermediate results, and it makes it easier to understand your code, because the variable names can help communicate intent.
-    You have multiple inputs or outputs. If there isn’t one primary object being transformed, but two or more objects being combined together, don’t use the pipe.
-    You are starting to think about a directed graph with a complex dependency structure. Pipes are fundamentally linear and expressing complex relationships with them will typically yield confusing code.


## Grouped summaries with `summarise()`

The last key verb is `summarise()`. It collapses a data frame to a single row.  `summarise()` is not terribly useful unless we pair it with `group_by()`. This changes the unit of analysis from the complete dataset to individual groups. Then, when you use the dplyr verbs on a grouped data frame they’ll be automatically applied “by group”. 

Together `group_by()` and `summarise()` provide one of the tools that you’ll use most commonly when working with dplyr: grouped summaries.

```{block2, type='rmdimportant'}
If you need to remove grouping, and return to operations on ungrouped data, use ungroup()
```


## Grouped mutates

Grouping is most useful in conjunction with `summarise()`, but you can also do convenient operations with `mutate()` and `filter()`

-    Find the best/worst members of each group.
-    Find all groups bigger/smaller than a threshold.
-    Standardize to compute per group metrics.

